{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import List\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实验2\n",
    "\n",
    "## 标准BP算法\n",
    "\n",
    "首先需要对数据进行归一化处理，便于神经网络的使用。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "# 读取所有数据（不包括第一行参数）\n",
    "wine_data = np.genfromtxt('wine_data.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# 读取所有特征数据，排除最后一列（列标签）\n",
    "X = wine_data[:, 0:13]\n",
    "# 标签列读取\n",
    "y = wine_data[:, 13]\n",
    "\n",
    "# 划分70%训练集，30%测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7)\n",
    "# 数据标准化\n",
    "label_train = LabelBinarizer().fit_transform(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "设置神经网络参数。包括学习率、迭代次数、神经节点设置。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "# 学习率\n",
    "rate = 0.11\n",
    "# 迭代次数\n",
    "step = 10000\n",
    "\n",
    "# 随机设置神经权值，13输入，3输出中间隐藏层100个神经元\n",
    "v = np.random.random((13, 100)) * 2 - 1  # 输入层->隐层\n",
    "w = np.random.random((100, 3)) * 2 - 1  # 隐层->输出层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "激活函数$sigmoid()$与其导数函数如下。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def de_sigmoid(x):\n",
    "    return x * (1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建训练函数\n",
    "标准BP算法核心要点如下：\n",
    "\n",
    "1. 随机初始化节点的权值。\n",
    "2. 按照激活函数公式计算出样本误差。\n",
    "3. 根据样本误差反推出权值梯度项。\n",
    "4. 更新节点权值。\n",
    "\n",
    "反复执行上述过程，直到达到设定的训练次数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orekimai/.conda/envs/MachineLearning/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 acc: 0.37037037037037035\n",
      "step: 1000 acc: 0.37037037037037035\n",
      "step: 2000 acc: 0.37037037037037035\n",
      "step: 3000 acc: 0.25925925925925924\n",
      "step: 4000 acc: 0.37037037037037035\n",
      "step: 5000 acc: 0.37037037037037035\n",
      "step: 6000 acc: 0.37037037037037035\n",
      "step: 7000 acc: 0.37037037037037035\n",
      "step: 8000 acc: 0.25925925925925924\n",
      "step: 9000 acc: 0.37037037037037035\n",
      "step: 10000 acc: 0.37037037037037035\n"
     ]
    }
   ],
   "source": [
    "def standard_bp_train(train_x, train_y, train_rate, train_step):\n",
    "    # 导入神经节点\n",
    "    global v, w\n",
    "    for n in range(train_step + 1):\n",
    "        # 随机选择样本\n",
    "        i = np.random.randint(train_x.shape[0])\n",
    "        x = train_x[i]\n",
    "        x = np.atleast_2d(x)\n",
    "\n",
    "        # 节点激活\n",
    "        L1 = sigmoid(np.dot(x, v))  # 输入层->隐层\n",
    "        L2 = sigmoid(np.dot(L1, w))  # 隐层->输出层\n",
    "\n",
    "        # 误差反向反馈\n",
    "        L2_delta = (train_y[i] - L2) * de_sigmoid(L2)  # 输出层->隐层\n",
    "        L1_delta = L2_delta.dot(w.T) * de_sigmoid(L1)  # 隐层->输入层\n",
    "\n",
    "        # 权值更新\n",
    "        w = w + train_rate * L1.T.dot(L2_delta)  # 隐层->输出层\n",
    "        v = v + train_rate * x.T.dot(L1_delta)  # 输入层->隐层\n",
    "\n",
    "        # 每1000次训练对网络进行测试，输出测试准确率\n",
    "        if n % 1000 == 0:\n",
    "            output = predict(x_test)\n",
    "            predictions = np.argmax(output, axis=1)  # 选择概率最大的输出点作为结果，输出所在列编号，对应分类结果\n",
    "            acc = np.mean(np.equal(predictions, y_test))  # 对比测试样本，求准确率\n",
    "            print(\"step:\", n, \"acc:\", acc)\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    L1 = sigmoid(np.dot(x, v))\n",
    "    L2 = sigmoid(np.dot(L1, w))\n",
    "    return L2\n",
    "\n",
    "\n",
    "standard_bp_train(x_train, label_train, rate, step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过运行标准BP算法可以发现，单层神经网络中神经点之间的权重在每次放入样本训练后都会发生改变，改变次数与训练次数相关，即：标准BP算法更新规则是基于每次样本而去修改。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 累计BP算法\n",
    "累计BP算法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "def sum_bp_train(train_x, train_y, train_rate, train_step):\n",
    "    return\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建神经网络\n",
    "\n",
    "使用TensorFlow搭建神经网络。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "# Import List\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, losses, datasets, Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建TensorFlow神经网络，设置输入层、隐藏层和输出层的大小。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "导入数据，并划分训练集与测试集。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "# 读取所有数据（不包括第一行参数）\n",
    "wine_data_tf = np.genfromtxt('wine_data.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# 读取所有特征数据，排除最后一列（列标签）\n",
    "X_tf = wine_data_tf[:, 0:13]\n",
    "# 标签列读取\n",
    "y_tf = wine_data_tf[:, 13]\n",
    "\n",
    "# 划分70%训练集，30%测试集\n",
    "x_train_tf, x_test_tf, y_train_tf, y_test_tf = train_test_split(X_tf, y_tf, test_size=0.3, train_size=0.7)\n",
    "# 数据标准化\n",
    "label_train_tf = LabelBinarizer().fit_transform(y_train_tf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# 使用keras的层堆叠创建神经网络，包含输入层、隐层和输出层\n",
    "model = tf.keras.Sequential([\n",
    "    # layers.Input(shape=x_train_tf.shape[1:]),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 参数设置\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 通过compile调整网络学习参数\n",
    "model.compile(\n",
    "    # 优化器\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    # 损失函数\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # 评估函数\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "向模型输入数据进行训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x_train_tf, label_train_tf,\n",
    "          batch_size=100,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test_tf, y_test_tf),\n",
    "          validation_freq=1)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}