{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import List\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实验2\n",
    "\n",
    "## 标准BP算法\n",
    "\n",
    "首先需要对数据进行归一化处理，便于神经网络的使用。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# 读取所有数据（不包括第一行参数）\n",
    "wine_data = np.genfromtxt('wine_data.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# 读取所有特征数据，排除最后一列（列标签）\n",
    "X = wine_data[:, 0:13]\n",
    "# 标签列读取\n",
    "y = wine_data[:, 13]\n",
    "\n",
    "# 划分70%训练集，30%测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7)\n",
    "# 数据标准化\n",
    "label_train = LabelBinarizer().fit_transform(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "设置神经网络参数。包括学习率、迭代次数、神经节点设置。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# 学习率\n",
    "rate = 0.11\n",
    "# 迭代次数\n",
    "step = 10000\n",
    "\n",
    "# 随机设置神经权值，13输入，3输出中间隐藏层100个神经元\n",
    "v = np.random.random((13, 100)) * 2 - 1 # 输入层->隐层\n",
    "w = np.random.random((100, 3)) * 2 - 1  # 隐层->输出层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "激活函数$sigmoid()$与其导数函数如下。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def de_sigmoid(x):\n",
    "    return x * (1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建训练函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orekimai/.conda/envs/MachineLearning/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 acc: 0.2962962962962963\n",
      "step: 1000 acc: 0.2962962962962963\n",
      "step: 2000 acc: 0.2962962962962963\n",
      "step: 3000 acc: 0.2222222222222222\n",
      "step: 4000 acc: 0.48148148148148145\n",
      "step: 5000 acc: 0.2962962962962963\n",
      "step: 6000 acc: 0.2962962962962963\n",
      "step: 7000 acc: 0.48148148148148145\n",
      "step: 8000 acc: 0.2222222222222222\n",
      "step: 9000 acc: 0.48148148148148145\n",
      "step: 10000 acc: 0.48148148148148145\n"
     ]
    }
   ],
   "source": [
    "def train(train_x, train_y, train_rate, train_step):\n",
    "    # 导入神经节点\n",
    "    global v, w\n",
    "    for n in range(train_step + 1):\n",
    "        # 随机选择样本\n",
    "        i = np.random.randint(train_x.shape[0])\n",
    "        x = train_x[i]\n",
    "        x = np.atleast_2d(x)\n",
    "\n",
    "        # 节点激活\n",
    "        L1 = sigmoid(np.dot(x, v))  # 输入层->隐层\n",
    "        L2 = sigmoid(np.dot(L1, w)) # 隐层->输出层\n",
    "\n",
    "        # 误差反向反馈\n",
    "        L2_delta = (train_y[i] - L2) * de_sigmoid(L2) # 输出层->隐层\n",
    "        L1_delta = L2_delta.dot(w.T) * de_sigmoid(L1)   # 隐层->输入层\n",
    "\n",
    "        # 权值更新\n",
    "        w = w + train_rate * L1.T.dot(L2_delta)   # 隐层->输出层\n",
    "        v = v + train_rate * x.T.dot(L1_delta)   # 输入层->隐层\n",
    "\n",
    "        # 每1000次训练对网络进行测试，输出测试准确率\n",
    "        if n % 1000 == 0:\n",
    "            output = predict(x_test)\n",
    "            predictions = np.argmax(output, axis=1) # 选择概率最大的输出点作为结果，输出所在列编号，对应分类结果\n",
    "            acc = np.mean(np.equal(predictions, y_test))    # 对比测试样本，求均值\n",
    "            print(\"step:\", n, \"acc:\", acc)\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    L1 = sigmoid(np.dot(x, v))\n",
    "    L2 = sigmoid(np.dot(L1, w))\n",
    "    return L2\n",
    "\n",
    "\n",
    "train(x_train, label_train, rate, step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 累计BP算法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建神经网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}