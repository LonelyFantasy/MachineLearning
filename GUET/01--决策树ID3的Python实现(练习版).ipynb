{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树ID3代码实现（Python语言）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/01.png\" width=\"300\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata():\n",
    "    dataSet = [[0, 0,0,0, 'no'],\n",
    "               [0, 0,0,1,'no'],\n",
    "               [0, 1,0,1, 'yes'],\n",
    "               [0, 1,1,0, 'yes'],\n",
    "               [0, 0,0,0, 'no'],\n",
    "               [1, 0,0,0, 'no'],\n",
    "               [1, 0,0,1, 'no'],\n",
    "               [1, 1,1,1, 'yes'],\n",
    "               [1, 0,1,2, 'yes'],\n",
    "               [1, 0,1,2, 'yes'],\n",
    "               [2, 0,1,2, 'yes'],\n",
    "               [2, 0,1,1, 'yes'],\n",
    "               [2, 1,0,1, 'yes'],\n",
    "               [2, 1,0,2, 'yes'],\n",
    "               [2, 0,0,0,'no']]\n",
    "    feature_name = ['age','job','house','credit']\n",
    "    return dataSet, feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example in dataSet:\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #特征数\n",
    "# n = len(dataSet[0])-1\n",
    "# #遍历每个特征\n",
    "# for i in range(n):  \n",
    "#   #获取当前特征的所有值\n",
    "#         featList = [example[i] for example in dataSet]   # 获取第i列特征的所有值\n",
    "# #         print(featList)\n",
    "#         #当前特征的可能取值\n",
    "#         uniqueVals = set(featList)\n",
    "# #         print(uniqueVals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算数据集的熵\n",
    "<img src=\"images/02.png\" width=\"200\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dataSet):\n",
    "    #数据集条数\n",
    "    m = len(dataSet)\n",
    "    \n",
    "    #标签不同类别的计数字典\n",
    "    labelCounts={}\n",
    "    #循环数据集\n",
    "    for featVec in dataSet:\n",
    "        #取标签\n",
    "        currentLabel = featVec[-1]\n",
    "        #如果字典中不存在，则值为0，否则值加1\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel]+=1\n",
    "    #保存最终的熵值\n",
    "    e = 0.0 \n",
    "    \n",
    "    #根据公式计算熵\n",
    "    for key in labelCounts:\n",
    "#         print(key)\n",
    "        prob = float(labelCounts[key])/m\n",
    "        e -= prob * log(prob,2)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：以下代码的输出结果应该是：0.971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, feature_name = loaddata()\n",
    "entropy(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从dataSet中取出第axis个特征的值为value样本，组成列表。去掉第第axis个特征。\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    #按轴和值划分好的数据集\n",
    "    retDataSet = []\n",
    "    #循环数据集\n",
    "    for featVec in dataSet:\n",
    "        #当前数据中，按轴取出第axis个特征的数值符合传入的value值的数据\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]   # 把前axis个特征的值，\n",
    "            reducedFeatVec.extend(featVec[axis+1:])  # 把第axis+1个特征的值，保存\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/04.png\" width=\"150\" height=\"50\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：以下代码的运行结果应该是\n",
    "[[0, 0, 0, 'no'],\n",
    " [0, 0, 1, 'no'],\n",
    " [0, 1, 1, 'yes'],\n",
    " [0, 0, 0, 'no'],\n",
    " [1, 0, 0, 'no'],\n",
    " [1, 0, 1, 'no'],\n",
    " [2, 1, 1, 'yes'],\n",
    " [2, 1, 2, 'yes'],\n",
    " [2, 0, 0, 'no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 'no'],\n",
       " [0, 0, 1, 'no'],\n",
       " [0, 1, 1, 'yes'],\n",
       " [0, 0, 0, 'no'],\n",
       " [1, 0, 0, 'no'],\n",
       " [1, 0, 1, 'no'],\n",
       " [2, 1, 1, 'yes'],\n",
       " [2, 1, 2, 'yes'],\n",
       " [2, 0, 0, 'no']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(dataSet,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择最好的特征\n",
    "<img src=\"images/03.png\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信息增益法选择最优划分属性\n",
    "def chooseBestFeature(dataSet):\n",
    "    #特征数\n",
    "    n = len(dataSet[0])-1\n",
    "    \n",
    "    #计数整个数据集的熵\n",
    "    baseEntropy = entropy(dataSet)\n",
    "    \n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    \n",
    "    #遍历每个特征\n",
    "    for i in range(n):  \n",
    "        #获取当前特征的所有值\n",
    "        featList = [example[i] for example in dataSet]  # 获取第i列特征的所有值\n",
    "        #当前特征的可能取值\n",
    "        uniqueVals = set(featList)\n",
    "        \n",
    "        #定义一临时变量保存当前的条件熵\n",
    "        newEntropy = 0.0\n",
    "        #循环每一个可能的取值\n",
    "        for value in uniqueVals:\n",
    "            #按该值进行数据集的划分\n",
    "            subDataSet = splitDataSet(dataSet,i,value)\n",
    "            \n",
    "            #计算条件熵（2行代码）\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob*entropy(subDataSet)\n",
    "            \n",
    "        #计算信息增益\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        \n",
    "        #保存当前最大的信息增益及对应的特征\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    #返回最优特征\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：运行下面的代码，正确返回值是：2，表示按第二个特征进行分裂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeature(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类别的投票表决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classVote(classList):\n",
    "    #定义一字典，记录每个标签对应的个数\n",
    "    classCount = {}\n",
    "    \n",
    "    #循环计数\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "        \n",
    "    #排序\n",
    "    print('classCount.items()=',classCount.items())\n",
    "    \n",
    "    sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(1),reverse=True)\n",
    "    print('sortedClassCount',sortedClassCount)\n",
    "    \n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：下面代码的返回结果应该是：yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classCount.items()= dict_items([('yes', 3), ('no', 2)])\n",
      "sortedClassCount [('yes', 3), ('no', 2)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classList= np.array(['yes','no','yes','no','yes'])\n",
    "classVote(classList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归训练一棵树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTree(dataSet,feature_name):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]  #所有类别都一致\n",
    "    \n",
    "    if len(dataSet[0]) == 1: #数据集中只剩下一个特征\n",
    "        return classVote(classList)\n",
    "    \n",
    "    bestFeat = chooseBestFeature(dataSet)\n",
    "    bestFeatName = feature_name[bestFeat]\n",
    "    myTree = {bestFeatName:{}}   # 决策树的数据结构：嵌套的字典\n",
    "    \n",
    "    # del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    \n",
    "    for value in uniqueVals:\n",
    "        sub_feature_name = feature_name[:]\n",
    "        myTree[bestFeatName][value] = trainTree(splitDataSet(dataSet, bestFeat, value),\n",
    "                                                sub_feature_name)\n",
    "    return myTree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'house': {0: {'job': {0: 'no', 1: 'yes'}}, 1: 'yes'}}\n"
     ]
    }
   ],
   "source": [
    "myDat,feature_name = loaddata()\n",
    "myTree = trainTree(myDat,feature_name)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputTree,feature_name,testVec):\n",
    "    print('inputTree.keys()=',inputTree.keys())\n",
    "    \n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    print('firstStr=',firstStr)\n",
    "    \n",
    "    secondDict = inputTree[firstStr]\n",
    "    print('secondDict=',secondDict)\n",
    "    \n",
    "    featIndex = feature_name.index(firstStr)\n",
    "    print('featIndex=',featIndex)\n",
    "    \n",
    "    key = testVec[featIndex]\n",
    "    print('key=',key)\n",
    "    \n",
    "    valueOfFeat = secondDict[key]\n",
    "    print('---------------------')\n",
    "    \n",
    "    if isinstance(valueOfFeat, dict): \n",
    "        classLabel = predict(valueOfFeat, feature_name, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "        \n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputTree.keys()= dict_keys(['house'])\n",
      "firstStr= house\n",
      "secondDict= {0: {'job': {0: 'no', 1: 'yes'}}, 1: 'yes'}\n",
      "featIndex= 2\n",
      "key= 0\n",
      "---------------------\n",
      "inputTree.keys()= dict_keys(['job'])\n",
      "firstStr= job\n",
      "secondDict= {0: 'no', 1: 'yes'}\n",
      "featIndex= 1\n",
      "key= 1\n",
      "---------------------\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# 输出预测\n",
    "print(predict(myTree,feature_name,[1,1,0,1]))   #  [1,1,0,1]为新样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
